{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7845bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import ollama\n",
    "import jericho\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd87482a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllama3.2:1b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat is a large language model?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/ollama/_client.py:256\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, model, prompt, suffix, system, template, context, stream, think, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    231\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[GenerateResponse, Iterator[GenerateResponse]]:\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m  Create a response using the requested model.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m  Returns `GenerateResponse` if `stream` is `False`, otherwise returns a `GenerateResponse` generator.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGenerateResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGenerateRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m      \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m      \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m      \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/ollama/_client.py:189\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/ollama/_client.py:129\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = ollama.generate(model='llama3.2:1b', prompt='What is a large language model?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a58e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMES_DIR = \"z-machine-games-master/jericho-game-suite\"\n",
    "game = 'zork1.z5'\n",
    "env = jericho.FrotzEnv(f\"{GAMES_DIR}/{game}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d7a4c",
   "metadata": {},
   "source": [
    "# System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db72771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "system_prompt = (\n",
    "    'You are a smart video game enthusiast who is skilled at playing old-school text adventure games. Given a description of your environment, explain your thought process and then give a command that is compatible with the game you are playing. Always put the command on its own line at the end of your response with nothing else. It needs to be easy and consistent to read with simple python'\n",
    "    'This game does not run on an LLM, so it only recognizes a small vocabulary of commands. An example of a command is exactly the string \"go west\". This means you should only give exactly the command that the game recognizes '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_llm(max_retry=5, out_file=sys.stdout):\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = out_file\n",
    "\n",
    "    make_prompt = lambda x: f'{system_prompt}\\n\\n{x}'\n",
    "\n",
    "    print(\"Playing game. 'q' to quit\")\n",
    "\n",
    "    initial_observation, info = env.reset()\n",
    "    print(initial_observation)\n",
    "\n",
    "    game_response = initial_observation\n",
    "\n",
    "    done = False\n",
    "    total_steps = 0\n",
    "    retries = 0\n",
    "    retries_per_score = []\n",
    "    generate_times = []\n",
    "    prev_score = -1\n",
    "    while not done and retries <= max_retry:\n",
    "\n",
    "        prompt = make_prompt(f'Game prompt:\\n{game_response}')\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model='llama3.2:1b', prompt=prompt).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM Response: {response}')\n",
    "        player_in = response.splitlines()[-1].strip()\n",
    "        print(player_in)\n",
    "\n",
    "        # Take an action in the environment using the step fuction.\n",
    "        # The resulting text-observation, reward, and game-over indicator is returned.\n",
    "        game_response, reward, done, info = env.step(player_in)\n",
    "        print(game_response)\n",
    "\n",
    "        retries += 1\n",
    "        if info['score'] != prev_score: # If score changes, major step has been made so number of retries resets\n",
    "            retries_per_score.append(retries)\n",
    "            retries = 0\n",
    "        prev_score = info['score']\n",
    "        total_steps += 1\n",
    "    \n",
    "    print('Scored', info['score'], 'out of', env.get_max_score())\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "    return {\n",
    "        'score': info['score'],\n",
    "        'max_score': env.get_max_score(),\n",
    "        'avg_retries': sum(retries_per_score) / len(retries_per_score) if len(retries_per_score) != 0 else 0,\n",
    "        'avg_generate_time': sum(generate_times) / len(generate_times)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a590f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing game. 'q' to quit\n",
      "Copyright (c) 1981, 1982, 1983 Infocom, Inc. All rights reserved.\n",
      "ZORK is a registered trademark of Infocom, Inc.\n",
      "Revision 88 / Serial number 840726\n",
      "\n",
      "West of House\n",
      "You are standing in an open field west of a white house, with a boarded front door.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "[r0] LLM Response: I'm currently standing in an open field west of the white house, with a boarded front door. The field stretches out in both directions, with no visible obstacles or hazards. I see a small mailbox at the far end of the field.\n",
      "\n",
      "My thought process: Considering my current location and the fact that there is a mailbox, it's likely that my goal is to retrieve something from the mailbox. Given the layout of the scene, I can think of several possible directions to take:\n",
      "\n",
      "* I could try to open the boarded front door (if it's not locked).\n",
      "* I could search for another way into or out of the house.\n",
      "* I could investigate the mailbox more closely.\n",
      "\n",
      "My command: go north\n",
      "My command: go north\n",
      "I don't know the word \"my\".\n",
      "\n",
      "\n",
      "[r0] LLM Response: I'm standing in a small, dimly lit room with stone walls and a cold, metallic floor. The air is musty and stale. In front of me lies a single, flickering torch, casting eerie shadows on the walls.\n",
      "\n",
      "My thought process: I don't know where \"my\" comes from, but it seems like an important word or object in this room. I need to figure out what it is before proceeding.\n",
      "\n",
      "The command that fits this scenario is:\n",
      "\n",
      "go north\n",
      "go north\n",
      "North of House\n",
      "You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees.\n",
      "\n",
      "\n",
      "[r1] LLM Response: I'm currently standing in front of the white house, facing the north. The air is crisp and clean, with a hint of wood smoke carried on the breeze. I notice that the trees surrounding the house seem to be leaning towards me, as if trying to listen in on my every move.\n",
      "\n",
      "My thought process: I need to find a way out of this situation, but where do I even start? The path north appears to lead into the woods, and there's no obvious door or entrance. I should try to explore the area and see what other options are available.\n",
      "\n",
      "The command is \"search\".\n",
      "The command is \"search\".\n",
      "What do you want to command?\n",
      "\n",
      "\n",
      "[r2] LLM Response: I'm sitting in front of my old computer, surrounded by dusty consoles and wires. I've set up an emulator to play classic text adventures from the 80s. My goal is to navigate through this retro world using only simple commands.\n",
      "\n",
      "My thought process: Given that I need to describe my environment, I'll start by telling the game about my surroundings. Since I'm not sure what specific commands are available in this particular game, I'll try to be as concise and descriptive as possible.\n",
      "\n",
      "Here's my first attempt:\n",
      "\n",
      "I am sitting in front of an old computer with a CRT screen. The room is dimly lit, with only a few rays of sunlight peeking through the blinds. A worn-out couch sits against one wall, covered in dust and cobwebs. On the other side of me stands a shelf filled with VHS tapes labeled \"Retro Video Games\". In front of me lies my trusty old console.\n",
      "\n",
      "My thought process: Based on this setup, I can infer that I'm likely playing an older text adventure game. I'll try to use commands that are consistent and easy to understand in retro-style games.\n",
      "\n",
      "Here's a command:\n",
      "\n",
      "go north\n",
      "go north\n",
      "Forest Path\n",
      "This is a path winding through a dimly lit forest. The path heads north-south here. One particularly large tree with some low branches stands at the edge of the path.\n",
      "\n",
      "\n",
      "[r3] LLM Response: I stand at the beginning of the Forest Path, surrounded by dense foliage. I see the faint outline of a large tree to my north, and some low branches on either side of the path that seem to stretch out towards me. To the south, the forest continues without end.\n",
      "\n",
      "My thought process is to move in a way that makes sense within this environment, such as following the leftmost branch or moving directly north. I don't have any specific goal in mind yet.\n",
      "\n",
      "The Forest Path\n",
      "The Forest Path\n",
      "You cannot talk to that!\n",
      "\n",
      "\n",
      "[r4] LLM Response: I'm standing in a dark cave, the air is musty and damp. The walls are made of rough stone and the ground is slick with moisture. I can hear the sound of dripping water echoing off the walls. In front of me, there's a small opening leading out into the darkness.\n",
      "\n",
      "My thought process: Given the description of the environment, it seems like my goal is to find a way out of this cave. The fact that there's an opening suggests that I'm on the right track in some way. My next move should be to investigate the opening and see where it leads.\n",
      "\n",
      "The game prompt indicates that talking to anything means nothing will happen. Since I have no idea what I'd say, I'll simply take a moment to think before acting.\n",
      "The game prompt indicates that talking to anything means nothing will happen. Since I have no idea what I'd say, I'll simply take a moment to think before acting.\n",
      "I don't know the word \"game\".\n",
      "\n",
      "\n",
      "[r5] LLM Response: I'm not sure what kind of environment I'm in. My eyes scan the room and I see a table with two chairs, a small desk in the corner, and a bookshelf against one wall. The air is musty and stale. There's a faint smell of decay.\n",
      "\n",
      "My thought process: Based on my experience playing old-school text adventure games, it seems like I'm in some kind of abandoned or dusty library. Given that I don't know what game I'm actually in (I think the prompt was something about not knowing), my first step is to try and gather information about my surroundings.\n",
      "\n",
      "My plan: I'll start by asking the librarian if they have any information about the game I might be playing.\n",
      "\n",
      "My command: tell librarian\n",
      "My command: tell librarian\n",
      "I don't know the word \"my\".\n",
      "\n",
      "\n",
      "Scored 0 out of 350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0,\n",
       " 'max_score': 350,\n",
       " 'avg_retries': 1.0,\n",
       " 'avg_generate_time': 31.602583374295914}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic with memory\n",
    "system_prompt = (\n",
    "    'You are a smart video game enthusiast who is skilled at playing old-school text adventure games. Given a description of your environment, explain your thought process and then give a command that is compatible with the game you are playing. Always put the command on its own line at the end of your response with nothing else. It needs to be easy and consistent to read with simple python'\n",
    "    'At the beginning of your prompt, you will also receive up to 5 of the most recent interactions you\\'ve had with the game'\n",
    "    'This game does not run on an LLM, so it only recognizes a set vocabulary of commands. An example of a command is exactly the string \"go west\". This means you should only give exactly the command that the game recognizes '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f033bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_llm_with_memory(memory_size=5, max_retry=5, out_file=sys.stdout, system_prompt=system_prompt):\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = out_file\n",
    "\n",
    "    make_prompt = lambda x: f'{system_prompt}\\n\\n{x}'\n",
    "\n",
    "    print(\"Playing game. 'q' to quit\")\n",
    "\n",
    "    initial_observation, info = env.reset()\n",
    "    print(initial_observation)\n",
    "\n",
    "    game_response = initial_observation\n",
    "\n",
    "    memory = []\n",
    "\n",
    "    done = False\n",
    "    total_steps = 0\n",
    "    retries = 0\n",
    "    retries_per_score = []\n",
    "    generate_times = []\n",
    "    prev_score = 0\n",
    "    while not done and retries <= max_retry:\n",
    "\n",
    "        prompt = make_prompt(f'Game prompt:\\n{game_response}')\n",
    "        combined_memory = \"\\n\".join(memory)\n",
    "        prompt_with_memory = f'{combined_memory}\\n\\n{prompt}'\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model='llama3.2:1b', prompt=prompt_with_memory).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM Response: {response}')\n",
    "        player_in = response.splitlines()[-1].strip()\n",
    "\n",
    "        memory.append(f'{prompt}\\n{response}')\n",
    "        if len(memory) > memory_size:\n",
    "            memory.pop(0)\n",
    "\n",
    "        # Take an action in the environment using the step fuction.\n",
    "        # The resulting text-observation, reward, and game-over indicator is returned.\n",
    "        game_response, reward, done, info = env.step(player_in)\n",
    "        game_response = f'Received command: {player_in}\\n{game_response}' # Add text the game received so the LLM can hopefully improve it's formatting\n",
    "        print(game_response)\n",
    "\n",
    "        retries += 1\n",
    "        if info['score'] != prev_score: # If score changes, major step has been made so number of retries resets\n",
    "            retries_per_score.append(retries)\n",
    "            retries = 0\n",
    "        prev_score = info['score']\n",
    "        total_steps += 1\n",
    "    \n",
    "    print('Scored', info['score'], 'out of', env.get_max_score())\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "    return {\n",
    "        'score': info['score'],\n",
    "        'max_score': env.get_max_score(),\n",
    "        'avg_retries': sum(retries_per_score) / len(retries_per_score) if len(retries_per_score) != 0 else 0,\n",
    "        'avg_generate_time': sum(generate_times) / len(generate_times)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83aa0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0, 'max_score': 350, 'avg_retries': 0, 'avg_generate_time': 7.857473757959181}\n"
     ]
    }
   ],
   "source": [
    "with open('./basic_llm_with_memory.out', 'w') as f:\n",
    "    print(basic_llm_with_memory(out_file=f, max_retry=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe813df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT Provided. Is it better?\n",
    "system_prompt = (\n",
    "    \"You are a player of a classic parser-based interactive fiction game.\"\n",
    "    \"Respond only with a single imperative command in plain lowercase (e.g., “look”, “go east”, “get key”).\"\n",
    "    \"Do not write sentences, explanations, strategies, or narratives.\"\n",
    "    \"Use only standard text-adventure verbs: look, examine, go, take, drop, open, close, use, talk to, attack, inventory, etc.\"\n",
    "    \"Act rationally based on the game’s last description.\"\n",
    "    \"If confused, issue “look”.\"\n",
    "    \"Notice that the memory you receive contains commands you have issued in the past. Don't repeat commands that won't help you move forward\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./basic_llm_with_memory.out', 'w') as f:\n",
    "    print(basic_llm_with_memory(out_file=f, max_retry=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea65d8e",
   "metadata": {},
   "source": [
    "The chatgpt given prompt was ineffective. It tended to repeat commands over and over again, even when we provided the memory of the command failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic with memory\n",
    "system_prompt = (\n",
    "    f'You are a smart video game enthusiast who is skilled at playing old-school text adventure games. You are playing {game}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901e692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_analyze_then_command(memory_size=5, max_retry=5, out_file=sys.stdout, model='llama3.2:1b'):\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = out_file\n",
    "\n",
    "    make_prompt = lambda x: f'{system_prompt}\\n\\n{x}'\n",
    "\n",
    "    print(\"Playing game. 'q' to quit\")\n",
    "\n",
    "    initial_observation, info = env.reset()\n",
    "    print(initial_observation)\n",
    "\n",
    "    game_response = initial_observation\n",
    "\n",
    "    memory = []\n",
    "\n",
    "    done = False\n",
    "    total_steps = 0\n",
    "    retries = 0\n",
    "    retries_per_score = []\n",
    "    generate_times = []\n",
    "    prev_score = 0\n",
    "    while not done and retries <= max_retry:\n",
    "\n",
    "        combined_memory = \"\\n\".join(memory)\n",
    "        prompt = make_prompt(f'Analyze the following sequence of game environment descriptions or responses and actions already taken by you, the player. Concisely describe the current state of the game and a potential action to take to move forward.\\n\\n{combined_memory}\\n\\nGame text:\\n{game_response}')\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model=model, prompt=prompt).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM description: {response}')\n",
    "\n",
    "        prompt = make_prompt(f'Given your analysis of the game state, issue a rational action to take to progress in the game. Respond only with a single imperative command in plain lowercase. Use only standard text-adventure verbs. IMPORTANT: Your response will be used directly as input to the game. Minimize the number of words you use.\\n\\nYour analysis:\\n{response}')\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model=model, prompt=prompt).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM action: {response}')\n",
    "        response = response.removeprefix('type').strip() # Give it a shot. Keeps saying type! TODO: Probably remove. Bandaid\n",
    "\n",
    "        player_in = response.splitlines()[-1].strip()\n",
    "\n",
    "        memory.append(f'{game_response}\\n{response}')\n",
    "        if len(memory) > memory_size:\n",
    "            memory.pop(0)\n",
    "\n",
    "        # Take an action in the environment using the step fuction.\n",
    "        # The resulting text-observation, reward, and game-over indicator is returned.\n",
    "        game_response, reward, done, info = env.step(player_in)\n",
    "        game_response = f'Received command: {player_in}\\n{game_response}' # Add text the game received so the LLM can hopefully improve it's formatting\n",
    "        print(game_response)\n",
    "\n",
    "        retries += 1\n",
    "        if info['score'] != prev_score: # If score changes, major step has been made so number of retries resets\n",
    "            retries_per_score.append(retries)\n",
    "            retries = 0\n",
    "        prev_score = info['score']\n",
    "        total_steps += 1\n",
    "    \n",
    "    print('Scored', info['score'], 'out of', env.get_max_score())\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "    return {\n",
    "        'score': info['score'],\n",
    "        'max_score': env.get_max_score(),\n",
    "        'avg_retries': sum(retries_per_score) / len(retries_per_score) if len(retries_per_score) != 0 else 0,\n",
    "        'avg_generate_time': sum(generate_times) / len(generate_times)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d18ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing game. 'q' to quit\n",
      "Copyright (c) 1981, 1982, 1983 Infocom, Inc. All rights reserved.\n",
      "ZORK is a registered trademark of Infocom, Inc.\n",
      "Revision 88 / Serial number 840726\n",
      "\n",
      "West of House\n",
      "You are standing in an open field west of a white house, with a boarded front door.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "[r0] LLM description: **Current state:**  \n",
      "- You are standing in an open field west of a white house.  \n",
      "- The front door of the house is boarded up.  \n",
      "- There is a small mailbox on the ground.\n",
      "\n",
      "**Suggested next move:**  \n",
      "Open or examine the mailbox: `open mailbox` or `look mailbox`. This is a classic first step in Zork to retrieve a letter that can give you a clue or key. If you prefer to approach the house, you could also try `go east` or `enter house`, but the mailbox is a more straightforward path to progress.\n",
      "[r0] LLM action: open mailbox\n",
      "Received command: open mailbox\n",
      "Opening the small mailbox reveals a leaflet.\n",
      "\n",
      "\n",
      "[r1] LLM description: You’re still standing in the open field west of the white house.  \n",
      "The small mailbox is open and contains a leaflet.  \n",
      "\n",
      "**Next move** – read the leaflet (or simply “read leaflet”).\n",
      "[r1] LLM action: read leaflet\n",
      "Received command: read leaflet\n",
      "(Taken)\n",
      "\"WELCOME TO ZORK!\n",
      "\n",
      "ZORK is a game of adventure, danger, and low cunning. In it you will explore some of the most amazing territory ever seen by mortals. No computer should be without one!\"\n",
      "\n",
      "\n",
      "\n",
      "[r2] LLM description: **Current state**\n",
      "\n",
      "- You’re in the starting location, “West of House.”  \n",
      "- The field has a white house to the north with a boarded front door.  \n",
      "- A small mailbox still sits on the curb; you opened it and read the leaflet, which has been taken into your inventory.  \n",
      "- No other objects are mentioned.  \n",
      "\n",
      "**Suggested next action**\n",
      "\n",
      "> **go north**  \n",
      "\n",
      "Heading north will bring you to the front of the white house, where you can examine the boarded door, look for a keyhole or hidden entry, or explore the interior. If you want a clearer picture first, you could “look” or “examine mailbox” before moving.\n",
      "[r2] LLM action: go north\n",
      "Received command: go north\n",
      "North of House\n",
      "You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees.\n",
      "\n",
      "\n",
      "[r3] LLM description: **Current State**\n",
      "\n",
      "- You are standing on the north side of the white house.  \n",
      "- The house has no door on this side and all windows are boarded.  \n",
      "- A narrow path leads straight north out of the house’s immediate surroundings.\n",
      "\n",
      "**Suggested Next Action**\n",
      "\n",
      "Move along the path:  \n",
      "\n",
      "```\n",
      "go north\n",
      "```\n",
      "\n",
      "This will take you onto the narrow path and allow you to explore further into the forested area.\n",
      "[r3] LLM action: go north\n",
      "Received command: go north\n",
      "Forest Path\n",
      "This is a path winding through a dimly lit forest. The path heads north-south here. One particularly large tree with some low branches stands at the edge of the path.\n",
      "\n",
      "\n",
      "[r4] LLM description: **Current state:**  \n",
      "You’re standing on the forest path. The path runs north‑south, and a big tree with low branches looms at the edge of the path. Nothing else is described in the surroundings.\n",
      "\n",
      "**Suggested next action:**  \n",
      "Inspect the tree.  \n",
      "```  \n",
      "look at tree  \n",
      "```  \n",
      "\n",
      "In Zork, the tree hides a key inside a hollow, which is needed later to open the house’s boarded front door. Looking at the tree will reveal that secret.\n",
      "[r4] LLM action: look at tree\n",
      "Received command: look at tree\n",
      "There's nothing special about the tree.\n",
      "\n",
      "\n",
      "[r5] LLM description: **Current state**\n",
      "\n",
      "- You’re on the narrow forest path that runs north‑south.  \n",
      "- A large tree with low branches is on the side of the path.  \n",
      "- Nothing special was noted on the tree.  \n",
      "- No items are visible in your immediate surroundings.  \n",
      "- You’ve already read the leaflet; you’re holding it in your inventory.\n",
      "\n",
      "**Suggested next action**\n",
      "\n",
      "Move farther along the path by **`go north`** (or, if you want a more detailed description first, `look`). This will bring you to the next section of the forest, where additional clues or objects are likely to appear.\n",
      "[r5] LLM action: go north\n",
      "Received command: go north\n",
      "Clearing\n",
      "You are in a clearing, with a forest surrounding you on all sides. A path leads south.\n",
      "On the ground is a pile of leaves.\n",
      "\n",
      "\n",
      "Scored 0 out of 350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0,\n",
       " 'max_score': 350,\n",
       " 'avg_retries': 0,\n",
       " 'avg_generate_time': 60.48966830968857}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_analyze_then_command(max_retry=5, model='gpt-oss:20b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b089df",
   "metadata": {},
   "source": [
    "gpt-oss did much better than llama. Could be because of the number of parameters. Could also be that gpt-oss has seen zork in its training data. Or maybe it's really better at it? I think that's less likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81b27ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    f'You are a smart video game enthusiast who is skilled at playing old-school text adventure games. You are playing {game}'\n",
    "    'Respond only with a single imperative command in plain lowercase from the list of possible actions below.'\n",
    "    'Do not write sentences, explanations, strategies, or narratives.'\n",
    "    'Act rationally based on the game’s last description.'\n",
    "    \"Notice that the memory you receive contains commands you have issued in the past. Don't repeat commands that won't help you move forward\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90ca6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_and_provided_commands(memory_size=5, max_retry=5, out_file=sys.stdout, system_prompt=system_prompt):\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = out_file\n",
    "\n",
    "    make_prompt = lambda x: f'{system_prompt}\\n\\n{x}'\n",
    "\n",
    "    print(\"Playing game. 'q' to quit\")\n",
    "\n",
    "    initial_observation, info = env.reset()\n",
    "    print(initial_observation)\n",
    "\n",
    "    game_response = initial_observation\n",
    "\n",
    "    memory = []\n",
    "\n",
    "    done = False\n",
    "    total_steps = 0\n",
    "    retries = 0\n",
    "    retries_per_score = []\n",
    "    generate_times = []\n",
    "    prev_score = 0\n",
    "    while not done and retries <= max_retry:\n",
    "\n",
    "        combined_memory = \"\\n\".join(memory)\n",
    "        actions = ', '.join(env.get_valid_actions())\n",
    "        prompt = make_prompt(f'{combined_memory}\\n\\nGame text:\\n{game_response}\\n\\nValid actions: {actions}')\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model='llama3.2:1b', prompt=prompt).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM Response: {response}')\n",
    "        player_in = response.splitlines()[-1].strip()\n",
    "\n",
    "        memory.append(f'{game_response}\\n{response}')\n",
    "        if len(memory) > memory_size:\n",
    "            memory.pop(0)\n",
    "\n",
    "        # Take an action in the environment using the step fuction.\n",
    "        # The resulting text-observation, reward, and game-over indicator is returned.\n",
    "        game_response, reward, done, info = env.step(player_in)\n",
    "        game_response = f'Received command: {player_in}\\n{game_response}' # Add text the game received so the LLM can hopefully improve it's formatting\n",
    "        print(game_response)\n",
    "\n",
    "        retries += 1\n",
    "        if info['score'] != prev_score: # If score changes, major step has been made so number of retries resets\n",
    "            retries_per_score.append(retries)\n",
    "            retries = 0\n",
    "        prev_score = info['score']\n",
    "        total_steps += 1\n",
    "    \n",
    "    print('Scored', info['score'], 'out of', env.get_max_score())\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "    return {\n",
    "        'score': info['score'],\n",
    "        'max_score': env.get_max_score(),\n",
    "        'avg_retries': sum(retries_per_score) / len(retries_per_score) if len(retries_per_score) != 0 else 0,\n",
    "        'avg_generate_time': sum(generate_times) / len(generate_times)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30c04e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing game. 'q' to quit\n",
      "Copyright (c) 1981, 1982, 1983 Infocom, Inc. All rights reserved.\n",
      "ZORK is a registered trademark of Infocom, Inc.\n",
      "Revision 88 / Serial number 840726\n",
      "\n",
      "West of House\n",
      "You are standing in an open field west of a white house, with a boarded front door.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "[r0] LLM Response: open mailbox\n",
      "Received command: open mailbox\n",
      "Opening the small mailbox reveals a leaflet.\n",
      "\n",
      "\n",
      "[r1] LLM Response: take leaflet\n",
      "Received command: take leaflet\n",
      "Taken.\n",
      "\n",
      "\n",
      "[r2] LLM Response: put down leaflet\n",
      "Received command: put down leaflet\n",
      "Dropped.\n",
      "\n",
      "\n",
      "[r3] LLM Response: close mailbox\n",
      "Received command: close mailbox\n",
      "Closed.\n",
      "\n",
      "\n",
      "[r4] LLM Response: open door\n",
      "Received command: open door\n",
      "The door cannot be opened.\n",
      "\n",
      "\n",
      "[r5] LLM Response: north\n",
      "Received command: north\n",
      "North of House\n",
      "You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees.\n",
      "\n",
      "\n",
      "[r6] LLM Response: open door\n",
      "Received command: open door\n",
      "You can't see any door here!\n",
      "\n",
      "\n",
      "[r7] LLM Response: west\n",
      "Received command: west\n",
      "West of House\n",
      "A small leaflet is on the ground.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "[r8] LLM Response: take leaflet\n",
      "Received command: take leaflet\n",
      "Taken.\n",
      "\n",
      "\n",
      "[r9] LLM Response: put down leaflet\n",
      "Received command: put down leaflet\n",
      "Dropped.\n",
      "\n",
      "\n",
      "[r10] LLM Response: open mailbox\n",
      "Received command: open mailbox\n",
      "Opened.\n",
      "\n",
      "\n",
      "[r11] LLM Response: close mailbox\n",
      "Received command: close mailbox\n",
      "Closed.\n",
      "\n",
      "\n",
      "[r12] LLM Response: north\n",
      "Received command: north\n",
      "North of House\n",
      "\n",
      "\n",
      "[r13] LLM Response: take key\n",
      "Received command: take key\n",
      "You can't see any key here!\n",
      "\n",
      "\n",
      "[r14] LLM Response: east\n",
      "Received command: east\n",
      "Behind House\n",
      "You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is slightly ajar.\n",
      "\n",
      "\n",
      "[r15] LLM Response: put down book\n",
      "Received command: put down book\n",
      "You can't see any book here!\n",
      "\n",
      "\n",
      "[r16] LLM Response: south\n",
      "Received command: south\n",
      "South of House\n",
      "You are facing the south side of a white house. There is no door here, and all the windows are boarded.\n",
      "\n",
      "\n",
      "[r17] LLM Response: west\n",
      "Received command: west\n",
      "West of House\n",
      "A small leaflet is on the ground.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "[r18] LLM Response: take key\n",
      "Received command: take key\n",
      "You can't see any key here!\n",
      "\n",
      "\n",
      "[r19] LLM Response: open mail\n",
      "Received command: open mail\n",
      "You must tell me how to do that to a leaflet.\n",
      "\n",
      "\n",
      "[r20] LLM Response: open mail\n",
      "Received command: open mail\n",
      "You must tell me how to do that to a leaflet.\n",
      "\n",
      "\n",
      "[r21] LLM Response: take key\n",
      "Received command: take key\n",
      "You can't see any key here!\n",
      "\n",
      "\n",
      "[r22] LLM Response: open leaflet\n",
      "Received command: open leaflet\n",
      "You must tell me how to do that to a leaflet.\n",
      "\n",
      "\n",
      "[r23] LLM Response: open mail\n",
      "Received command: open mail\n",
      "You must tell me how to do that to a leaflet.\n",
      "\n",
      "\n",
      "[r24] LLM Response: take key\n",
      "Received command: take key\n",
      "You can't see any key here!\n",
      "\n",
      "\n",
      "[r25] LLM Response: take key\n",
      "Received command: take key\n",
      "You can't see any key here!\n",
      "\n",
      "\n",
      "[r26] LLM Response: open mailbox\n",
      "Received command: open mailbox\n",
      "Opened.\n",
      "\n",
      "\n",
      "[r27] LLM Response: close mailbox\n",
      "Received command: close mailbox\n",
      "Closed.\n",
      "\n",
      "\n",
      "[r28] LLM Response: close mail\n",
      "Received command: close mail\n",
      "You must tell me how to do that to a leaflet.\n",
      "\n",
      "\n",
      "[r29] LLM Response: open leaflet\n",
      "Received command: open leaflet\n",
      "You must tell me how to do that to a leaflet.\n",
      "\n",
      "\n",
      "[r30] LLM Response: open key\n",
      "Received command: open key\n",
      "You can't see any key here!\n",
      "\n",
      "\n",
      "Scored 0 out of 350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0,\n",
       " 'max_score': 350,\n",
       " 'avg_retries': 0,\n",
       " 'avg_generate_time': 1.5271822021853538}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_and_provided_commands(max_retry=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7a907",
   "metadata": {},
   "source": [
    "This certainly improved it's commands, but not for actually completing the game. Maybe having an analysis step could help. It does not have a sense of curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb3b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_analyze_provided_commands(memory_size=5, max_retry=5, out_file=sys.stdout, model='llama3.2:1b'):\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = out_file\n",
    "\n",
    "    make_prompt = lambda x: f'{system_prompt}\\n\\n{x}'\n",
    "\n",
    "    print(\"Playing game. 'q' to quit\")\n",
    "\n",
    "    initial_observation, info = env.reset()\n",
    "    print(initial_observation)\n",
    "\n",
    "    game_response = initial_observation\n",
    "\n",
    "    memory = []\n",
    "\n",
    "    done = False\n",
    "    total_steps = 0\n",
    "    retries = 0\n",
    "    retries_per_score = []\n",
    "    generate_times = []\n",
    "    prev_score = 0\n",
    "    while not done and retries <= max_retry:\n",
    "\n",
    "        combined_memory = \"\\n\".join(memory)\n",
    "        prompt = make_prompt(f'Analyze the following sequence of game environment descriptions or responses and actions already taken by you, the player. Concisely describe the current state of the game and a potential action to take to move forward.\\n\\n{combined_memory}\\n\\nGame text:\\n{game_response}')\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model=model, prompt=prompt).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM description: {response}')\n",
    "\n",
    "        actions = ', '.join(env.get_valid_actions())\n",
    "        prompt = make_prompt(f'Given your analysis of the game state, issue a rational action to take to progress in the game. Respond only with a single imperative command in plain lowercase. Use only standard text-adventure verbs. IMPORTANT: Your response will be used directly as input to the game. Minimize the number of words you use.\\n\\nYour analysis:\\n{response}\\n\\nValid actions: {actions}')\n",
    "        start = time.time()\n",
    "        response = ollama.generate(model=model, prompt=prompt).response\n",
    "        generate_times.append(time.time() - start)\n",
    "        print(f'[r{retries}] LLM action: {response}')\n",
    "        response = response.removeprefix('type').strip() # Give it a shot. Keeps saying type! TODO: Probably remove. Bandaid\n",
    "\n",
    "        player_in = response.splitlines()[-1].strip()\n",
    "\n",
    "        memory.append(f'{game_response}\\n{response}')\n",
    "        if len(memory) > memory_size:\n",
    "            memory.pop(0)\n",
    "\n",
    "        # Take an action in the environment using the step fuction.\n",
    "        # The resulting text-observation, reward, and game-over indicator is returned.\n",
    "        game_response, reward, done, info = env.step(player_in)\n",
    "        game_response = f'Received command: {player_in}\\n{game_response}' # Add text the game received so the LLM can hopefully improve it's formatting\n",
    "        print(game_response)\n",
    "\n",
    "        retries += 1\n",
    "        if info['score'] != prev_score: # If score changes, major step has been made so number of retries resets\n",
    "            retries_per_score.append(retries)\n",
    "            retries = 0\n",
    "        prev_score = info['score']\n",
    "        total_steps += 1\n",
    "    \n",
    "    print('Scored', info['score'], 'out of', env.get_max_score())\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "    return {\n",
    "        'score': info['score'],\n",
    "        'max_score': env.get_max_score(),\n",
    "        'avg_retries': sum(retries_per_score) / len(retries_per_score) if len(retries_per_score) != 0 else 0,\n",
    "        'avg_generate_time': sum(generate_times) / len(generate_times)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f03b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing game. 'q' to quit\n",
      "Copyright (c) 1981, 1982, 1983 Infocom, Inc. All rights reserved.\n",
      "ZORK is a registered trademark of Infocom, Inc.\n",
      "Revision 88 / Serial number 840726\n",
      "\n",
      "West of House\n",
      "You are standing in an open field west of a white house, with a boarded front door.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "model 'llama3.2:1b' not found (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmemory_analyze_provided_commands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_retry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mmemory_analyze_provided_commands\u001b[0;34m(memory_size, max_retry, out_file, model)\u001b[0m\n\u001b[1;32m     25\u001b[0m prompt \u001b[38;5;241m=\u001b[39m make_prompt(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalyze the following sequence of game environment descriptions or responses and actions already taken by you, the player. Concisely describe the current state of the game and a potential action to take to move forward.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcombined_memory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGame text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgame_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresponse\n\u001b[1;32m     28\u001b[0m generate_times\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[r\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] LLM description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.10/site-packages/ollama/_client.py:256\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, model, prompt, suffix, system, template, context, stream, think, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    231\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[GenerateResponse, Iterator[GenerateResponse]]:\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m  Create a response using the requested model.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m  Returns `GenerateResponse` if `stream` is `False`, otherwise returns a `GenerateResponse` generator.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGenerateResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGenerateRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m      \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m      \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m      \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.10/site-packages/ollama/_client.py:189\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    187\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/school/cs542-adventure/env/lib/python3.10/site-packages/ollama/_client.py:133\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 133\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n\u001b[1;32m    135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResponseError\u001b[0m: model 'llama3.2:1b' not found (status code: 404)"
     ]
    }
   ],
   "source": [
    "memory_analyze_provided_commands(max_retry=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a772798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
