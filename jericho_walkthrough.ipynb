{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23391fa9-06a8-489d-9570-74081de4c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "game_files = glob.glob(\"./z-machine-games-master/jericho-game-suite/*.z5\")\n",
    "\n",
    "model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\" #\"unsloth/llama-3-8b-bnb-4bit\"\n",
    "chat_template_name = \"llama-3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c83854d-2728-44cf-880f-b07ffcba30df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jericho\n",
    "\n",
    "\n",
    "def get_steps(filename: str):\n",
    "    env = jericho.FrotzEnv(filename)\n",
    "    \n",
    "    initial_obs, info = env.reset()\n",
    "    walkthrough = env.get_walkthrough()\n",
    "\n",
    "    steps = []\n",
    "    \n",
    "    obs = initial_obs\n",
    "    for step in walkthrough:\n",
    "        steps.append((obs, step))\n",
    "        #print(obs, step)\n",
    "        obs, reward, done, info = env.step(step)\n",
    "        #print(reward)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    return steps\n",
    "\n",
    "\n",
    "steps = []\n",
    "for game_file in game_files:\n",
    "    steps.append(get_steps(game_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd80df7-b54c-4274-9ef6-a24282d04574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "{'conversations': [{'from': 'human', 'value': '\\nWelcome to Adventure!\\n\\nMurdac\\nAn adventure game by Jonathan R. Partington (Cambridge University, 1982)\\n[This translation: version 1.111115 / Phoenix v1.04 / Inform v6.32\\nPlease type \"inform\" for further details.]\\n\\nWelcome to the Land of Murdac. This is version 1.07.\\n\\nType HELP for basic information, and BLURB for the full story.\\nAll comments to JRP1 please. New commands BRIEF/TERSE,\\nNORMAL/STANDARD, VERBOSE and EXAMINE have now been added.\\nYou are standing outside the door of a small flint hut.\\nThere are paths off to the east, west and south.\\nThe door is locked'}, {'from': 'gpt', 'value': 's'}, {'from': 'human', 'value': '\\nYou are in a garden of luxurious flowers. There are paths to\\nthe north, east and south'}, {'from': 'gpt', 'value': 'n'}, {'from': 'human', 'value': '\\nYou are in a rock garden. There are paths to the east, southeast\\nand south'}, {'from': 'gpt', 'value': 's'}, {'from': 'human', 'value': '\\nYou are in a garden of exotic vegetables. There are paths to the\\nnorth, east and south'}, {'from': 'gpt', 'value': 'n'}, {'from': 'human', 'value': '\\nThe south-north path ends at a nearly-completed brick wall.\\nThere is a still a gap through which you can pass.\\nTwo ogres here are busily engaged in building activities.\\nThey take no notice of you'}, {'from': 'gpt', 'value': 'n'}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b488824037754e1bba3fe7d78135ae7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Standardizing formats (num_proc=32):   0%|          | 0/1637 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from unsloth import standardize_sharegpt\n",
    "\n",
    "def steps_to_dataset(steps: list[list[tuple[str, str]]], length: int):\n",
    "    convos = []\n",
    "\n",
    "    for game in steps:\n",
    "        convo = []\n",
    "        n = 0\n",
    "        \n",
    "        for step in game:\n",
    "            convo.append({\"from\": \"human\", \"value\": step[0]})\n",
    "            convo.append({\"from\": \"gpt\", \"value\": step[1]})\n",
    "            n += 1\n",
    "            if length > 0 and n >= length:\n",
    "                n = 0\n",
    "                convos.append(convo)\n",
    "                convo = []\n",
    "\n",
    "        if len(convo) > 0:\n",
    "            convos.append(convo)\n",
    "\n",
    "    return Dataset.from_dict({\"conversations\": convos})\n",
    "\n",
    "dataset = steps_to_dataset(steps, 5)\n",
    "print(dataset[0])\n",
    "dataset = standardize_sharegpt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223d3b69-4da1-4a06-a1ff-c73f77b21641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.57.2.\n",
      "   \\\\   /|    NVIDIA RTX 4000 Ada Generation. Num GPUs = 1. Max memory: 19.548 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Taken from this article:\n",
    "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/tutorial-how-to-finetune-llama-3-and-use-in-ollama\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f39db7-3ad7-47ca-89ff-8de35c019d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.11.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                     \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f13ef1-048d-4226-a278-c2aee7ee51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(tokenizer, chat_template = chat_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a5d126-807f-447c-bfb3-e4c9e817b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/a/grad/elewark/cs542/cs542-adventure/venv/lib/python3.13/site-packages/dill/_dill.py:422: PicklingWarning: Cannot locate reference to <class 'bytearray_iterator'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/s/chopin/a/grad/elewark/cs542/cs542-adventure/venv/lib/python3.13/site-packages/dill/_dill.py:422: PicklingWarning: Cannot pickle <class 'bytearray_iterator'>: builtins.bytearray_iterator has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Parameter 'function'=<function formatting_prompts_func at 0x7fbea0468ea0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only shown once. Subsequent hashing failures won't be shown.\n",
      "[datasets.fingerprint|WARNING]Parameter 'function'=<function formatting_prompts_func at 0x7fbea0468ea0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only shown once. Subsequent hashing failures won't be shown.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d7b47e002141a49e9386c0e81d1101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1637 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/datasets-guide\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt = False)\n",
    "        for convo in convos\n",
    "    ]\n",
    "    return {'text': texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "#dataset[0]\n",
    "#dataset[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc874d6-1545-4581-bd32-a3cf8cb29ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/chopin/a/grad/elewark/cs542/cs542-adventure/venv/lib/python3.13/site-packages/dill/_dill.py:422: PicklingWarning: Cannot locate reference to <class 'bytearray_iterator'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/s/chopin/a/grad/elewark/cs542/cs542-adventure/venv/lib/python3.13/site-packages/dill/_dill.py:422: PicklingWarning: Cannot pickle <class 'bytearray_iterator'>: builtins.bytearray_iterator has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e7cf0c9d094f8ea64112e8ce583970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/1637 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1617e352e3c4c57bf8b2ddc5a3ac577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=36):   0%|          | 0/1637 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "enable_bf16 = is_bfloat16_supported()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    formatting_func = formatting_prompts_func,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,\n",
    "        # num_train_epochs = 1,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not enable_bf16,\n",
    "        bf16 = enable_bf16,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1089b039-b171-4fdf-b595-e63cb73da07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,637 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 01:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.945600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.927800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.682600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.200800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.313500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.272200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.692200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.901500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.376800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.168900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.438400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.727600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.979300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.963400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.822900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.629700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.305100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d77698-9a11-4954-9703-39c197133ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/chat_template.jinja',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc7a3a61-365e-4daa-b345-52b005ab4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "def make_message(role, content):\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "\n",
    "def get_input_ids(messages):\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt = True,\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "\n",
    "def generate_response(messages):\n",
    "    input_ids = get_input_ids(messages)\n",
    "\n",
    "    output_ids = model.generate(input_ids,\n",
    "        max_new_tokens = 128,\n",
    "    )\n",
    "    out = tokenizer.batch_decode(output_ids)\n",
    "    \n",
    "    out_line = out[0]\n",
    "    start_token = \"<|end_header_id|>\"\n",
    "    end_token = tokenizer.eos_token\n",
    "    \n",
    "    start_index = out_line.rindex(start_token) + len(start_token)\n",
    "    end_index = out_line.rindex(end_token)\n",
    "    \n",
    "    return out_line[start_index : end_index].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703bd1e2-f699-4484-aacd-f0531cc9b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [make_message(\"user\", \"You are in a room. You see an egg on a table and a chest of drawers.\")]\n",
    "generate_response(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37008dd3-85b2-4c66-a72d-3f879114f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x sword'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [make_message(\"user\", \"You are in a cave. In front of you lies a sword sticking out of a large boulder.\")]\n",
    "generate_response(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e8c0c00-e76a-405a-ad59-5c67c9a5bd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copyright (c) 1981, 1982, 1983 Infocom, Inc. All rights reserved.\n",
      "ZORK is a registered trademark of Infocom, Inc.\n",
      "Revision 88 / Serial number 840726\n",
      "\n",
      "West of House\n",
      "You are standing in an open field west of a white house, with a boarded front door.\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "> X\n",
      "I don't know the word \"x\".\n",
      "\n",
      "\n",
      "> x\n",
      "I don't know the word \"x\".\n",
      "\n",
      "\n",
      "> read book\n",
      "You can't see any book here!\n",
      "\n",
      "\n",
      "> E\n",
      "The door is boarded and you can't remove the boards.\n",
      "\n",
      "\n",
      "> n\n",
      "North of House\n",
      "You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees.\n",
      "\n",
      "\n",
      "> W\n",
      "West of House\n",
      "There is a small mailbox here.\n",
      "\n",
      "\n",
      "> GET MAILBOX\n",
      "It is securely anchored.\n",
      "\n",
      "\n",
      "> E\n",
      "The door is boarded and you can't remove the boards.\n",
      "\n",
      "\n",
      "> E\n",
      "The door is boarded and you can't remove the boards.\n",
      "\n",
      "\n",
      "> GET KEY\n",
      "You can't see any key here!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_game(game_filename: str, n_steps: int, with_history: bool):\n",
    "    env = jericho.FrotzEnv(game_filename)\n",
    "\n",
    "    messages = []\n",
    "    \n",
    "    obs, info = env.reset()\n",
    "    print(obs)\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        if not with_history:\n",
    "            messages.clear()\n",
    "\n",
    "        messages.append(make_message(\"user\", obs))\n",
    "        \n",
    "        response = generate_response(messages)\n",
    "        print(\">\", response)\n",
    "        messages.append(make_message(\"assistant\", response))\n",
    "        \n",
    "        obs, reward, done, info = env.step(response)\n",
    "        print(obs)\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "run_game(\"./z-machine-games-master/jericho-game-suite/zork1.z5\", 10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
